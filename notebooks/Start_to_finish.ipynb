{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start to finish\n",
    "rough draft to implement in pycharm project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "#import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select tap sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepared, reserved test clip recorded same as train\n",
    "#clip = '../../../Source/Clean_train_clips/Test_pad/Ball_change/1/15.wav'\n",
    "\n",
    "# Audio extracted from youtube\n",
    "clip = '../../../Source/Shuffle/4/1.wav'\n",
    "\n",
    "clip_path = Path(clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play sound\n",
    "AudioSegment.from_wav(clip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters (set in training and validation)\n",
    "clip_length = 20772\n",
    "n_mfcc = 20\n",
    "frame_length = 256\n",
    "hop_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_signal(path, length):\n",
    "    samples, sample_rate = librosa.load(path)\n",
    "    if len(samples) < length:\n",
    "        y = np.pad(samples, (0, length-len(samples)), 'constant')\n",
    "    elif len(samples) > length:\n",
    "        y = samples[:length]\n",
    "    else:\n",
    "        y = samples\n",
    "    return y, sample_rate\n",
    "\n",
    "def get_features_mfcc(samples, sample_rate):\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=samples, sr=sample_rate, n_mfcc=n_mfcc).T,axis=0)\n",
    "    return mfccs\n",
    "\n",
    "def get_features_zcr(samples, sample_rate):\n",
    "    zcr = librosa.feature.zero_crossing_rate(samples, frame_length=frame_length, hop_length=hop_length)\n",
    "    return zcr\n",
    "    \n",
    "def get_features_energy(samples, sample_rate) :\n",
    "    energy = np.array([sum(abs(samples[i:i+frame_length]**2)) for i in range (0, len(samples), hop_length)])\n",
    "    return energy\n",
    "\n",
    "def get_features_rmse(samples, sample_rate):\n",
    "    rmse = librosa.feature.rmse(samples, frame_length=frame_length, hop_length=hop_length, center=True)\n",
    "    return rmse[0]\n",
    "\n",
    "def get_features_bpm(samples, sample_rate): \n",
    "    onset_env = librosa.onset.onset_strength(samples, sr=sample_rate) # Assumes static tempo, for dynamic: aggregate=None\n",
    "    tempo = librosa.beat.tempo(onset_envelope=onset_env, sr=sample_rate)\n",
    "    return tempo\n",
    "\n",
    "def get_label(path):\n",
    "    if path.parts[-3] == 'Shuffle':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad with ending silence or cut to set length\n",
    "y, sr = resize_signal(clip_path, clip_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features\n",
    "mfcc = get_features_mfcc (y, sr)[:,np.newaxis]\n",
    "zcr = get_features_zcr (y, sr).T\n",
    "energy = get_features_energy(y, sr)[:,np.newaxis]\n",
    "rmse = get_features_rmse (y, sr)[:,np.newaxis]\n",
    "bpm = get_features_bpm (y, sr)[:,np.newaxis]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set = (mfcc, zcr, energy,rmse, bpm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine features to form input for model\n",
    "inputs = np.concatenate(feature_set, axis=0).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trained models\n",
    "#model = ('../src/train/trained_models/one_hidden_mfcc_zcr_energy_rmse_bpm.pt')\n",
    "#model = ('../src/train/trained_models/one_hidden_mfcc_zcr_energy_rmse_bpm_128.pt')\n",
    "model = ('../src/train/trained_models/one_hidden_mfcc_zcr_energy_rmse_bpm_256.pt')\n",
    "#model = ('../src/train/trained_models/two_hidden_mfcc_zcr_energy_rmse_bpm.pt')\n",
    "\n",
    "#model = ('../src/train/trained_models/one_hidden_mfcc_128.pt')\n",
    "#model = ('../src/train/trained_models/two_hidden_mfcc.pt')\n",
    "#model = ('../src/train/trained_models/one_hidden_mfcc_bpm_128.pt')\n",
    "#model = ('../src/train/trained_models/two_hidden_mfcc_bpm.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device('cpu')\n",
    "\n",
    "inputs = torch.tensor(inputs, device=device, dtype=dtype)\n",
    "\n",
    "# Load model\n",
    "model = torch.load(model)\n",
    "\n",
    "outputs = model(inputs)\n",
    "\n",
    "y_pred = (torch.argmax(outputs.data).numpy())\n",
    "\n",
    "true = get_label(clip_path)\n",
    "\n",
    "print(\"What's on tap?\")\n",
    "print()\n",
    "if y_pred == 1:\n",
    "    print('Predicted: Shuffle')\n",
    "elif y_pred == 0:\n",
    "    print('Predicted: Ball change')\n",
    "print()\n",
    "if true == 1:\n",
    "    print('It was a Shuffle.')\n",
    "elif true == 0:\n",
    "    print('It was a Ball change.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What did that sound like again?\n",
    "AudioSegment.from_wav(clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
