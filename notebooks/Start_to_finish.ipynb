{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start to finish\n",
    "rough draft to implement in pycharm project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "#import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select tap sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepared, reserved test clip recorded same as train\n",
    "#clip = '../../../Source/Clean_train_clips/Test_pad/Ball_change/1/15.wav'\n",
    "\n",
    "# Audio extracted from youtube\n",
    "clip = '../../../Source/Shuffle/4/1.wav'\n",
    "\n",
    "clip_path = Path(clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play sound\n",
    "AudioSegment.from_wav(clip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters (set in training and validation)\n",
    "clip_length = 20772\n",
    "n_mfcc = 20\n",
    "frame_length = 256\n",
    "hop_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_signal(path, length):\n",
    "    samples, sample_rate = librosa.load(path)\n",
    "    if len(samples) < length:\n",
    "        y = np.pad(samples, (0, length-len(samples)), 'constant')\n",
    "    elif len(samples) > length:\n",
    "        y = samples[:length]\n",
    "    else:\n",
    "        y = samples\n",
    "    return y, sample_rate\n",
    "\n",
    "def get_features_mfcc(samples, sample_rate):\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=samples, sr=sample_rate, n_mfcc=n_mfcc).T,axis=0)\n",
    "    return mfccs\n",
    "\n",
    "def get_features_zcr(samples, sample_rate):\n",
    "    zcr = librosa.feature.zero_crossing_rate(samples, frame_length=frame_length, hop_length=hop_length)\n",
    "    return zcr\n",
    "    \n",
    "def get_features_energy(samples, sample_rate) :\n",
    "    energy = np.array([sum(abs(samples[i:i+frame_length]**2)) for i in range (0, len(samples), hop_length)])\n",
    "    return energy\n",
    "\n",
    "def get_features_rmse(samples, sample_rate):\n",
    "    rmse = librosa.feature.rmse(samples, frame_length=frame_length, hop_length=hop_length, center=True)\n",
    "    return rmse[0]\n",
    "\n",
    "def get_features_bpm(samples, sample_rate): \n",
    "    onset_env = librosa.onset.onset_strength(samples, sr=sample_rate) # Assumes static tempo, for dynamic: aggregate=None\n",
    "    tempo = librosa.beat.tempo(onset_envelope=onset_env, sr=sample_rate)\n",
    "    return tempo\n",
    "\n",
    "def get_label(path):\n",
    "    if path.parts[-3] == 'Shuffle':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad with ending silence or cut to set length\n",
    "y, sr = resize_signal(clip_path, clip_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features\n",
    "mfcc = get_features_mfcc (y, sr)[:,np.newaxis]\n",
    "zcr = get_features_zcr (y, sr).T\n",
    "energy = get_features_energy(y, sr)[:,np.newaxis]\n",
    "rmse = get_features_rmse (y, sr)[:,np.newaxis]\n",
    "bpm = get_features_bpm (y, sr)[:,np.newaxis]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set = (mfcc, zcr, energy,rmse, bpm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine features to form input for model\n",
    "inputs = np.concatenate(feature_set, axis=0).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trained models\n",
    "#model = ('../src/train/trained_models/one_hidden_mfcc_zcr_energy_rmse_bpm.pt')\n",
    "#model = ('../src/train/trained_models/one_hidden_mfcc_zcr_energy_rmse_bpm_128.pt')\n",
    "model = ('../src/train/trained_models/one_hidden_mfcc_zcr_energy_rmse_bpm_256.pt')\n",
    "#model = ('../src/train/trained_models/two_hidden_mfcc_zcr_energy_rmse_bpm.pt')\n",
    "\n",
    "#model = ('../src/train/trained_models/one_hidden_mfcc_128.pt')\n",
    "#model = ('../src/train/trained_models/two_hidden_mfcc.pt')\n",
    "#model = ('../src/train/trained_models/one_hidden_mfcc_bpm_128.pt')\n",
    "#model = ('../src/train/trained_models/two_hidden_mfcc_bpm.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device('cpu')\n",
    "\n",
    "inputs = torch.tensor(inputs, device=device, dtype=dtype)\n",
    "\n",
    "# Load model\n",
    "model = torch.load(model)\n",
    "\n",
    "outputs = model(inputs)\n",
    "\n",
    "y_pred = (torch.argmax(outputs.data).numpy())\n",
    "\n",
    "true = get_label(clip_path)\n",
    "\n",
    "print(\"What's on tap?\")\n",
    "print()\n",
    "if y_pred == 1:\n",
    "    print('Predicted: Shuffle')\n",
    "elif y_pred == 0:\n",
    "    print('Predicted: Ball change')\n",
    "print()\n",
    "if true == 1:\n",
    "    print('It was a Shuffle.')\n",
    "elif true == 0:\n",
    "    print('It was a Ball change.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What did that sound like again?\n",
    "AudioSegment.from_wav(clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters (set in training and validation)\n",
    "clip_length = 20772\n",
    "n_mfcc = 20\n",
    "frame_length = 256\n",
    "hop_length = 128\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Feature generating functions\n",
    "\n",
    "class Features :\n",
    "    def __init__(self, samples, sample_rate, clip_length, n_mfcc, frame_length, hop_length, feature_set):\n",
    "        self.samples = samples\n",
    "        self.sample_rate = sample_rate\n",
    "        self.clip_length = clip_length\n",
    "        self.n_mfcc = n_mfcc\n",
    "        self.frame_length = frame_length\n",
    "        self.hop_length = hop_length\n",
    "        self.feature_set = feature_set\n",
    "\n",
    "\n",
    "    def get_features_mfcc(self):\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=self.samples,\n",
    "                                             sr=self.sample_rate,\n",
    "                                             n_mfcc=self.n_mfcc).T, axis=0)\n",
    "        return mfccs[:,np.newaxis]\n",
    "\n",
    "\n",
    "    def get_features_zcr(self):\n",
    "        zcr = librosa.feature.zero_crossing_rate(self.samples,\n",
    "                                                 frame_length=self.frame_length,\n",
    "                                                 hop_length=self.hop_length)\n",
    "        return zcr.T\n",
    "\n",
    "\n",
    "    def get_features_energy(self):\n",
    "        energy = np.array([sum(abs(self.samples[i:i + self.frame_length] ** 2))\n",
    "                           for i in range(0, len(self.samples), self.hop_length)])\n",
    "        return energy[:,np.newaxis]\n",
    "\n",
    "\n",
    "    def get_features_rmse(self):\n",
    "        rmse = librosa.feature.rmse(self.samples,\n",
    "                                    frame_length=self.frame_length,\n",
    "                                    hop_length=self.hop_length,\n",
    "                                    center=True)\n",
    "        return rmse[0][:,np.newaxis]\n",
    "\n",
    "\n",
    "    def get_features_bpm(self):\n",
    "        onset_env = librosa.onset.onset_strength(self.samples,\n",
    "                                                 sr=self.sample_rate)  # Assumes static tempo, dynamic:aggregate=None\n",
    "        tempo = librosa.beat.tempo(onset_envelope=onset_env, sr=self.sample_rate)\n",
    "        return tempo[:,np.newaxis]\n",
    "\n",
    "    def get_feature_array(self):\n",
    "        feature_array = np.empty([1,1])\n",
    "        for i in self.feature_set:\n",
    "            #print(i)\n",
    "            if i == 'mfcc':\n",
    "                feature_array = np.concatenate((feature_array, self.get_features_mfcc()), \n",
    "                                               axis=0)\n",
    "            if i == 'zcr':  \n",
    "                feature_array = np.concatenate((feature_array, self.get_features_zcr()), \n",
    "                                               axis=0)\n",
    "            if i == 'energy':\n",
    "                feature_array = np.concatenate((feature_array, self.get_features_energy()), \n",
    "                                               axis=0)\n",
    "            if i == 'rmse':\n",
    "                feature_array = np.concatenate((feature_array, self.get_features_rmse()), \n",
    "                                               axis=0)\n",
    "            if i == 'bpm':\n",
    "                feature_array = np.concatenate((feature_array, self.get_features_bpm()), \n",
    "                                               axis=0)\n",
    "        feature_array = feature_array.flatten()\n",
    "        feature_array = np.delete(feature_array, 0)\n",
    "        return feature_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, sample_rate = librosa.load('../../../Source/Shuffle/4/1.wav')\n",
    "feature_set = ['mfcc']\n",
    "\n",
    "\n",
    "\n",
    "new_features = Features(samples=samples,\n",
    "                       sample_rate=sample_rate,\n",
    "                       clip_length=clip_length,\n",
    "                       n_mfcc=n_mfcc,\n",
    "                       frame_length=frame_length,\n",
    "                       hop_length=hop_length,\n",
    "                       feature_set=feature_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = new_features.get_feature_array().flatten()\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.89198211e+02,  9.24704301e+01,  4.30348416e+00,  3.81261584e+01,\n",
       "        8.64961635e+00,  1.31438377e+01, -4.60695814e+00,  2.24177103e+00,\n",
       "       -2.67799977e+00,  3.44075743e+00, -5.87519003e+00,  3.71596183e+00,\n",
       "       -9.14437899e-01, -3.78216182e+00, -7.21278726e+00,  4.23203655e+00,\n",
       "       -3.32227059e+00, -2.75906450e+00, -6.45973520e+00,  2.88711983e-01])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
